{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé¨ Stranger Things NLP with AWS SageMaker\n",
        "\n",
        "This comprehensive tutorial shows you how to use AWS SageMaker to scale your Stranger Things NLP project for production.\n",
        "\n",
        "## What You'll Learn\n",
        "1. Setting up SageMaker infrastructure\n",
        "2. Training character chatbot models at scale\n",
        "3. Deploying models as auto-scaling endpoints\n",
        "4. Monitoring and cost optimization\n",
        "5. Building production-ready applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Prerequisites\n",
        "\n",
        "Before running this notebook, make sure you have:\n",
        "\n",
        "1. **AWS Account** with appropriate permissions\n",
        "2. **AWS CLI** configured with your credentials\n",
        "3. **Environment variables** set:\n",
        "   - `AWS_ACCOUNT_ID`\n",
        "   - `HUGGINGFACE_TOKEN`\n",
        "4. **Python dependencies** installed from requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages if not already installed\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Core packages\n",
        "packages = ['boto3', 'sagemaker', 'pandas', 'matplotlib', 'seaborn']\n",
        "\n",
        "for package in packages:\n",
        "    try:\n",
        "        __import__(package)\n",
        "    except ImportError:\n",
        "        install_package(package)\n",
        "\n",
        "print(\"‚úÖ All packages installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Part 1: Setting Up SageMaker Infrastructure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import boto3\n",
        "from pathlib import Path\n",
        "\n",
        "# Add parent directory to path to import our modules\n",
        "sys.path.append(str(Path().absolute().parent))\n",
        "\n",
        "from config import SageMakerConfigManager, create_default_sagemaker_config\n",
        "from storage import SageMakerS3Manager\n",
        "from training_orchestrator import SageMakerTrainingOrchestrator\n",
        "from deployment_manager import SageMakerDeploymentManager\n",
        "from monitoring import SageMakerMonitoring\n",
        "\n",
        "print(\"üì¶ SageMaker modules imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check environment setup\n",
        "print(\"üîç Environment Check:\")\n",
        "print(f\"AWS Region: {os.getenv('AWS_DEFAULT_REGION', 'us-east-1')}\")\n",
        "print(f\"AWS Account ID: {os.getenv('AWS_ACCOUNT_ID', 'Not Set')}\")\n",
        "print(f\"HuggingFace Token: {'‚úÖ Set' if os.getenv('HUGGINGFACE_TOKEN') else '‚ùå Not Set'}\")\n",
        "\n",
        "# Test AWS credentials\n",
        "try:\n",
        "    sts = boto3.client('sts')\n",
        "    identity = sts.get_caller_identity()\n",
        "    print(f\"AWS Identity: {identity['Arn']}\")\n",
        "    print(\"‚úÖ AWS credentials are working!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå AWS credentials issue: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create SageMaker configuration\n",
        "print(\"‚öôÔ∏è Creating SageMaker configuration...\")\n",
        "\n",
        "# Set your custom bucket name here\n",
        "username = os.getenv('USER', 'demo')\n",
        "bucket_name = f\"stranger-things-sagemaker-{username}\"\n",
        "\n",
        "config = create_default_sagemaker_config(bucket_name)\n",
        "print(f\"‚úÖ Configuration created with bucket: {bucket_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize SageMaker components\n",
        "print(\"üèóÔ∏è Initializing SageMaker components...\")\n",
        "\n",
        "s3_manager = SageMakerS3Manager(bucket_name=config.s3_config.bucket_name)\n",
        "training_orchestrator = SageMakerTrainingOrchestrator(config)\n",
        "deployment_manager = SageMakerDeploymentManager(config)\n",
        "monitoring = SageMakerMonitoring(config)\n",
        "\n",
        "print(\"‚úÖ All components initialized!\")\n",
        "print(f\"üìä S3 Bucket: {s3_manager.bucket_name}\")\n",
        "print(f\"üéØ Training Instance: {config.training_config.instance_type}\")\n",
        "print(f\"üöÄ Inference Instance: {config.endpoint_config.instance_type}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Part 2: Data Preparation and Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample training data for demonstration\n",
        "import pandas as pd\n",
        "import tempfile\n",
        "\n",
        "print(\"üìù Creating sample training data...\")\n",
        "\n",
        "# Sample dialogue data (replace with your actual data)\n",
        "sample_data = [\n",
        "    {\"name\": \"Eleven\", \"line\": \"Friends don't lie.\"},\n",
        "    {\"name\": \"Mike\", \"line\": \"Will, are you okay?\"},\n",
        "    {\"name\": \"Eleven\", \"line\": \"I can find him.\"},\n",
        "    {\"name\": \"Joyce\", \"line\": \"Where is my son?\"},\n",
        "    {\"name\": \"Eleven\", \"line\": \"The Upside Down is cold and dark.\"},\n",
        "    {\"name\": \"Dustin\", \"line\": \"We need to find the gate.\"},\n",
        "    {\"name\": \"Eleven\", \"line\": \"Papa... he's gone.\"},\n",
        "    {\"name\": \"Steve\", \"line\": \"I can protect you guys.\"},\n",
        "    {\"name\": \"Eleven\", \"line\": \"I'm the monster.\"},\n",
        "    {\"name\": \"Hopper\", \"line\": \"Kid, you did good.\"},\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(sample_data)\n",
        "print(f\"üìã Created sample dataset with {len(df)} entries\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save data locally and upload to S3\n",
        "with tempfile.TemporaryDirectory() as temp_dir:\n",
        "    temp_path = Path(temp_dir)\n",
        "    data_file = temp_path / \"training_data.csv\"\n",
        "    \n",
        "    # Save CSV file\n",
        "    df.to_csv(data_file, index=False)\n",
        "    print(f\"üíæ Saved training data to: {data_file}\")\n",
        "    \n",
        "    # Upload to S3\n",
        "    print(\"üì§ Uploading training data to S3...\")\n",
        "    training_data_uri = training_orchestrator.prepare_training_data(\n",
        "        str(temp_path), \"chatbot\"\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Training data uploaded to: {training_data_uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÇ Part 3: Training Models with SageMaker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure training job\n",
        "import time\n",
        "\n",
        "job_name = f\"stranger-things-demo-{int(time.time())}\"\n",
        "print(f\"üöÇ Launching training job: {job_name}\")\n",
        "\n",
        "# For demo purposes, we'll use smaller settings\n",
        "hyperparameters = {\n",
        "    'base_model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
        "    'batch_size': '1',\n",
        "    'max_steps': '10',  # Small number for demo\n",
        "    'learning_rate': '2e-4',\n",
        "    'gradient_accumulation_steps': '2'\n",
        "}\n",
        "\n",
        "# Note: In real usage, you would set max_steps to 1000+ for proper training\n",
        "print(\"‚ö†Ô∏è Note: Using minimal training steps for demo purposes\")\n",
        "print(\"In production, increase max_steps to 1000+ for better results\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Launch training job\n",
        "print(\"üöÄ Launching SageMaker training job...\")\n",
        "print(\"This may take 15-30 minutes depending on instance startup and training\")\n",
        "\n",
        "try:\n",
        "    job_arn = training_orchestrator.launch_training_job(\n",
        "        job_name=job_name,\n",
        "        model_type=\"chatbot\",\n",
        "        training_data_s3_uri=training_data_uri,\n",
        "        hyperparameters=hyperparameters\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Training job launched successfully!\")\n",
        "    print(f\"üìä Job Name: {job_name}\")\n",
        "    print(f\"üìã Job ARN: {job_arn}\")\n",
        "    \n",
        "    # Store job name for later use\n",
        "    current_job_name = job_name\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Training job launch failed: {e}\")\n",
        "    print(\"This might be due to:\")\n",
        "    print(\"1. IAM role not configured properly\")\n",
        "    print(\"2. Docker image not available\")\n",
        "    print(\"3. AWS service limits reached\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor training job status\n",
        "def check_training_status(job_name, max_checks=10):\n",
        "    \"\"\"Check training job status with progress updates\"\"\"\n",
        "    \n",
        "    for i in range(max_checks):\n",
        "        try:\n",
        "            status_info = training_orchestrator.get_job_status(job_name)\n",
        "            status = status_info['status']\n",
        "            \n",
        "            print(f\"üìä Check {i+1}/{max_checks}: Status = {status}\")\n",
        "            \n",
        "            if status == 'Completed':\n",
        "                print(\"‚úÖ Training completed successfully!\")\n",
        "                return True\n",
        "            elif status == 'Failed':\n",
        "                failure_reason = status_info.get('failure_reason', 'Unknown')\n",
        "                print(f\"‚ùå Training failed: {failure_reason}\")\n",
        "                return False\n",
        "            elif status in ['InProgress', 'Starting']:\n",
        "                print(\"‚è≥ Training in progress...\")\n",
        "                if i < max_checks - 1:  # Don't sleep on last iteration\n",
        "                    time.sleep(60)  # Wait 1 minute between checks\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error checking status: {e}\")\n",
        "    \n",
        "    print(\"‚è∞ Reached maximum status checks\")\n",
        "    return None\n",
        "\n",
        "# Check status (this will take a while for real training)\n",
        "if 'current_job_name' in locals():\n",
        "    print(f\"üîç Monitoring training job: {current_job_name}\")\n",
        "    training_completed = check_training_status(current_job_name)\nelse:\n    print(\"‚ö†Ô∏è No training job to monitor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Part 4: Model Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deploy the trained model (if training completed)\n",
        "if 'current_job_name' in locals() and 'training_completed' in locals() and training_completed:\n",
        "    print(f\"üöÄ Deploying model from training job: {current_job_name}\")\n",
        "    \n",
        "    try:\n",
        "        # Deploy the model\n",
        "        deployment_info = deployment_manager.deploy_model_complete(\n",
        "            model_name=f\"{current_job_name}-model\",\n",
        "            model_artifacts_s3_uri=f\"s3://{s3_manager.bucket_name}/models/{current_job_name}/output/model.tar.gz\"\n",
        "        )\n",
        "        \n",
        "        endpoint_name = deployment_info['endpoint_name']\n",
        "        print(f\"‚úÖ Deployment initiated successfully!\")\n",
        "        print(f\"üîó Endpoint Name: {endpoint_name}\")\n",
        "        print(f\"‚è≥ Endpoint creation takes 5-10 minutes...\")\n",
        "        \n",
        "        # Store endpoint name for later use\n",
        "        current_endpoint_name = endpoint_name\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Deployment failed: {e}\")\nelse:\n    print(\"‚ö†Ô∏è No completed training job to deploy\")\n    print(\"For demo purposes, let's use a pre-existing model if available...\")\n    \n    # List existing endpoints\n    endpoints = deployment_manager.list_active_endpoints()\n    if endpoints:\n        current_endpoint_name = endpoints[0]['name']\n        print(f\"üìã Using existing endpoint: {current_endpoint_name}\")\n    else:\n        print(\"üìã No existing endpoints found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wait for endpoint to be ready (if we have one)\n",
        "if 'current_endpoint_name' in locals():\n",
        "    print(f\"‚è≥ Waiting for endpoint to be ready: {current_endpoint_name}\")\n",
        "    \n",
        "    # Check endpoint status\n",
        "    max_checks = 10\n",
        "    for i in range(max_checks):\n",
        "        status_info = deployment_manager.get_endpoint_status(current_endpoint_name)\n",
        "        status = status_info['status']\n",
        "        \n",
        "        print(f\"üìä Check {i+1}/{max_checks}: Endpoint Status = {status}\")\n",
        "        \n",
        "        if status == 'InService':\n",
        "            print(\"‚úÖ Endpoint is ready for inference!\")\n",
        "            endpoint_ready = True\n",
        "            break\n",
        "        elif status == 'Failed':\n",
        "            failure_reason = status_info.get('failure_reason', 'Unknown')\n",
        "            print(f\"‚ùå Endpoint failed: {failure_reason}\")\n",
        "            endpoint_ready = False\n",
        "            break\n",
        "        else:\n",
        "            print(f\"‚è≥ Endpoint status: {status}...\")\n",
        "            if i < max_checks - 1:\n",
        "                time.sleep(60)  # Wait 1 minute between checks\n",
        "    else:\n",
        "        print(\"‚è∞ Reached maximum endpoint checks\")\n",
        "        endpoint_ready = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Part 5: Testing Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test inference (if endpoint is ready)\n",
        "if 'current_endpoint_name' in locals() and 'endpoint_ready' in locals() and endpoint_ready:\n",
        "    print(f\"üß™ Testing inference on endpoint: {current_endpoint_name}\")\n",
        "    \n",
        "    # Test messages\n",
        "    test_messages = [\n",
        "        \"Hello Eleven, how are you?\",\n",
        "        \"What do you think about the Upside Down?\",\n",
        "        \"Can you help us find Will?\"\n",
        "    ]\n",
        "    \n",
        "    for i, message in enumerate(test_messages, 1):\n",
        "        print(f\"\\nüî∏ Test {i}: {message}\")\n",
        "        \n",
        "        try:\n",
        "            # Create payload\n",
        "            payload = {\n",
        "                \"inputs\": message,\n",
        "                \"parameters\": {\n",
        "                    \"max_length\": 128,\n",
        "                    \"temperature\": 0.7,\n",
        "                    \"do_sample\": True\n",
        "                }\n",
        "            }\n",
        "            \n",
        "            # Invoke endpoint\n",
        "            response = deployment_manager.invoke_endpoint(current_endpoint_name, payload)\n",
        "            print(f\"ü§ñ Response: {response}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Inference failed: {e}\")\n",
        "\nelse:\n    print(\"‚ö†Ô∏è No ready endpoint for testing\")\n    print(\"In a real scenario, you would wait for endpoint deployment to complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Part 6: Monitoring and Analytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up monitoring dashboard\n",
        "print(\"üìä Setting up CloudWatch monitoring...\")\n",
        "\n",
        "try:\n",
        "    dashboard_url = monitoring.create_dashboard(\"StrangerThings-Demo-Dashboard\")\n",
        "    print(f\"‚úÖ CloudWatch dashboard created!\")\n",
        "    print(f\"üîó Dashboard URL: {dashboard_url}\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Dashboard creation failed: {e}\")\n    print(\"This might be due to CloudWatch permissions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create monitoring alarms (if we have an endpoint)\n",
        "if 'current_endpoint_name' in locals():\n",
        "    print(f\"üîî Setting up alarms for endpoint: {current_endpoint_name}\")\n",
        "    \n",
        "    try:\n",
        "        alarms = monitoring.create_alarms(current_endpoint_name)\n",
        "        print(f\"‚úÖ Created {len(alarms)} monitoring alarms:\")\n",
        "        for alarm in alarms:\n",
        "            print(f\"  üì¢ {alarm}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Alarm creation failed: {e}\")\nelse:\n    print(\"‚ö†Ô∏è No endpoint available for alarm setup\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate monitoring report\n",
        "print(\"üìã Generating monitoring report...\")\n",
        "\n",
        "report = monitoring.generate_monitoring_report(\n",
        "    endpoint_name=current_endpoint_name if 'current_endpoint_name' in locals() else None,\n",
        "    training_job_name=current_job_name if 'current_job_name' in locals() else None\n",
        ")\n",
        "\nprint(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí∞ Part 7: Cost Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze costs\n",
        "print(\"üí∞ Analyzing SageMaker costs...\")\n",
        "\n",
        "try:\n",
        "    cost_data = monitoring.get_cost_metrics(days_back=7)\n",
        "    \n",
        "    if 'error' not in cost_data:\n",
        "        print(f\"üìä Total Cost (last 7 days): ${cost_data['total_cost']:.2f}\")\n",
        "        print(f\"üìà Daily Average: ${cost_data['daily_average']:.2f}\")\n",
        "        \n",
        "        if cost_data['services']:\n",
        "            print(\"\\nüîç Cost Breakdown by Service:\")\n",
        "            for service, data in cost_data['services'].items():\n",
        "                print(f\"  ‚Ä¢ {service}: ${data['total']:.2f}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Cost data retrieval failed: {cost_data['error']}\")\n",
        "        print(\"This might be due to Cost Explorer API permissions\")\n",
        "        \nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Cost analysis failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Part 8: Production Best Practices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up auto-scaling (if we have an endpoint)\n",
        "if 'current_endpoint_name' in locals() and 'endpoint_ready' in locals() and endpoint_ready:\n",
        "    print(f\"üìà Setting up auto-scaling for: {current_endpoint_name}\")\n",
        "    \n",
        "    try:\n",
        "        success = deployment_manager.setup_auto_scaling(\n",
        "            endpoint_name=current_endpoint_name,\n",
        "            min_capacity=1,\n",
        "            max_capacity=3,  # Conservative for demo\n",
        "            target_value=50   # Scale when reaching 50 invocations per instance\n",
        "        )\n",
        "        \n",
        "        if success:\n",
        "            print(\"‚úÖ Auto-scaling configured successfully!\")\n",
        "            print(\"üìä Configuration:\")\n",
        "            print(\"  ‚Ä¢ Min Instances: 1\")\n",
        "            print(\"  ‚Ä¢ Max Instances: 3\")\n",
        "            print(\"  ‚Ä¢ Target: 50 invocations per instance\")\n",
        "        else:\n",
        "            print(\"‚ùå Auto-scaling setup failed\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Auto-scaling setup failed: {e}\")\nelse:\n    print(\"‚ö†Ô∏è No ready endpoint for auto-scaling setup\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show deployment summary\n",
        "print(\"üìã Deployment Summary\")\nprint(\"=\" * 40)\n\nsummary = deployment_manager.get_deployment_summary()\nprint(f\"üöÄ Active Endpoints: {summary['endpoints']}\")\nprint(f\"üì¶ Registered Models: {summary['models']}\")\nprint(f\"‚öôÔ∏è Batch Jobs: {summary['batch_jobs']}\")\n\nif summary['active_endpoints']:\n    print(\"\\nüîó Endpoint Names:\")\n    for endpoint in summary['active_endpoints']:\n        print(f\"  ‚Ä¢ {endpoint}\")\n\nif summary['active_models']:\n    print(\"\\nüì¶ Model Names:\")\n    for model in summary['active_models']:\n        print(f\"  ‚Ä¢ {model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üßπ Part 9: Cleanup (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMPORTANT: Uncomment the following cell only if you want to clean up resources\n",
        "# This will delete endpoints and incur no further charges\n",
        "\n",
        "cleanup_resources = False  # Set to True if you want to cleanup\n",
        "\nif cleanup_resources:\n    print(\"üßπ Cleaning up resources...\")\n    print(\"‚ö†Ô∏è This will delete endpoints and stop charges\")\n    \n    # Delete endpoint if it exists\n    if 'current_endpoint_name' in locals():\n        try:\n            success = deployment_manager.delete_endpoint(\n                current_endpoint_name, \n                delete_config=True, \n                delete_model=False  # Keep model for future use\n            )\n            \n            if success:\n                print(f\"‚úÖ Deleted endpoint: {current_endpoint_name}\")\n            else:\n                print(f\"‚ùå Failed to delete endpoint: {current_endpoint_name}\")\n                \n        except Exception as e:\n            print(f\"‚ö†Ô∏è Cleanup error: {e}\")\n    \n    print(\"‚úÖ Cleanup completed!\")\n    print(\"üí° Models and training data are preserved in S3\")\nelse:\n    print(\"‚ö†Ô∏è Cleanup skipped (cleanup_resources = False)\")\n    print(\"üí° Remember to delete endpoints when you're done to avoid charges\")\n    print(\"üí° You can do this through the AWS Console or by running:\")\n    if 'current_endpoint_name' in locals():\n        print(f\"    deployment_manager.delete_endpoint('{current_endpoint_name}')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Congratulations!\n",
        "\n",
        "You've successfully completed the Stranger Things NLP SageMaker tutorial! Here's what you accomplished:\n",
        "\n",
        "### ‚úÖ What You Built\n",
        "1. **üèóÔ∏è SageMaker Infrastructure** - S3 buckets, configurations, and IAM roles\n",
        "2. **üöÇ Scalable Training** - Cloud-based model training with GPU instances\n",
        "3. **üöÄ Auto-scaling Endpoints** - Production-ready inference with auto-scaling\n",
        "4. **üìä Monitoring & Alerts** - CloudWatch dashboards and alarm system\n",
        "5. **üí∞ Cost Optimization** - Cost tracking and optimization strategies\n",
        "\n",
        "### üöÄ Next Steps\n",
        "1. **Scale Your Data** - Train with larger datasets for better performance\n",
        "2. **Multi-Character Models** - Train separate models for different characters\n",
        "3. **A/B Testing** - Deploy multiple model versions for comparison\n",
        "4. **Production App** - Integrate endpoints with your Gradio application\n",
        "5. **MLOps Pipeline** - Set up automated retraining and deployment\n",
        "\n",
        "### üìö Additional Resources\n",
        "- [SageMaker Documentation](https://docs.aws.amazon.com/sagemaker/)\n",
        "- [HuggingFace on SageMaker](https://huggingface.co/docs/sagemaker/index)\n",
        "- [Cost Optimization Guide](https://aws.amazon.com/sagemaker/pricing/)\n",
        "\n",
        "### üí° Tips for Production\n",
        "- Use spot instances for training to save up to 70% on costs\n",
        "- Set up CloudWatch alarms for proactive monitoring\n",
        "- Implement proper security with VPC and IAM policies\n",
        "- Use model versioning for reliable deployments\n",
        "- Regular cost reviews and optimization\n",
        "\n",
        "**Happy scaling with AWS SageMaker! üé¨‚ú®**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}